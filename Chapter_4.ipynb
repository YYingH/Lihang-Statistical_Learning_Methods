{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Naive Bayes** method is a classification method based on Bayes' theorem and independent assumptions of feature conditions. For a given training data set, first learn the joint probability distribution of the input and output based one the feature independent assumption; then based on this model, use the Bayes theorem to find the posterior probability $y$ for the given input $x$.\n",
    "\n",
    "1. Naive Bayes method is a typical generative learning method. It learned by calculate the joint probability dributribution $P(X, Y)$ to get the posterior probability distribution $P(Y|X)$. Specifically, use the training data to learn the estimates of A and B to get the joint probability distribution:\n",
    "\n",
    "$$P(X, Y) = P(Y)P(X|Y)$$\n",
    "\n",
    "The probability estimation method can be a maximum likelihood estimation or a Bayesian estimation.\n",
    "\n",
    "\n",
    "2. The basic assumption of the Naive Bayesian method is conditional independence, \n",
    "\n",
    "$$\\begin{matrix}\n",
    "P(X=x|Y=c_k) & = P(X^{(1)} = x^{(1)}, ..., X^{(n)} = x^{(n)} | Y=c_k)  \\\\ \n",
    " & =\\prod_{j=1}^{n}P(X^{(j)} = x^{(j)}|Y = c_k)\n",
    "\\end{matrix}$$\n",
    "\n",
    "This is a strong assumption. Because of this assumption, the number of conditional probabilities contained in the model is greatly reduced, and the learning and prediction of the naive Bayes method is greatly simplified. So naive Bayesian method is efficient and easy to implement. The disadvantage is that the performance of classification is not necessarily high.\n",
    "\n",
    "3. Naive Bayes method uses Bayes theorem and learned joint probability model to make classification prediction.\n",
    "\n",
    "$$P(Y|X) = \\frac{P(X,Y)}{P(X} = \\frac{P(Y)P(X|Y)}{\\sum_YP(Y)P(X|Y)}$$\n",
    "\n",
    "4. Divides input x into the class y with the largest posterior probability.\n",
    "\n",
    "$$y =\\arg \\max_{c_k}P(c_k|X=x) \\\\= \\arg max_{c_{k}}P(Y = c_k)\\prod_{j=1}^{n}P(X_j = x^{(j)}|Y=c_k)$$\n",
    "\n",
    "\n",
    "5. The maximum posterior probability is equivalent to the expected risk minimization when the loss function is 0-1.\n",
    "\n",
    "model:\n",
    "\n",
    "- Gaussian model\n",
    "\n",
    "- Polynomial model\n",
    "\n",
    "- Bernoulli model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from collections import Counter\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data():\n",
    "    iris = load_iris()\n",
    "    df = pd.DataFrame(iris.data, columns = iris.feature_names)\n",
    "    df['label'] = iris.target\n",
    "    df.columns = ['sepal length','sepal width','petal length', 'petal width', 'label']\n",
    "    data = np.array(df.iloc[:100, :])\n",
    "    return data[:, :-1], data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_data()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6.3, 3.3, 4.7, 1.6]), 1.0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0], y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The likelihood of features is assumed to be Gaussian\n",
    "\n",
    "Probability density function:\n",
    "\n",
    "$$P(x_i| y_k) = \\frac{1}{\\sqrt{2\\pi\\delta^{2}_{yk}}}\\exp (-\\frac{(x_i - \\mu_{yk})^2}{2\\delta^{2}_{yk}})$$\n",
    "\n",
    "Mathematical Expectation: $\\mu$\n",
    "\n",
    "\n",
    "Variance: $\\delta ^2 = \\frac{\\sum (X - \\mu)^2}{N}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "    \n",
    "    #Mathematical Expection\n",
    "    @staticmethod\n",
    "    def mean(X):\n",
    "        return sum(X)/float(len(X))\n",
    "    \n",
    "    #Variance\n",
    "    def stdev(self, X):\n",
    "        avg = self.mean(X)\n",
    "        return math.sqrt(sum([pow(x - avg, 2) for x in X]) / float(len(X)))\n",
    "    \n",
    "    #Probability density function\n",
    "    def gaussian_probability(self, x, mean, stdev):\n",
    "        exponent = math.exp(-(math.pow(x - mean, 2) / \n",
    "                             (2 * math.pow(stdev, 2))))\n",
    "        return (1 / (math.sqrt(2*math.pi)*stdev)) * exponent\n",
    "    \n",
    "    #deal with X_train\n",
    "    def summarize(self, train_data):\n",
    "        summarize = [(self.mean(i), self.stdev(i)) for i in zip(*train_data)]\n",
    "        return summarize\n",
    "    \n",
    "    #Find mathematical expectations and standard deviations by category\n",
    "    def fit(self, X, y):\n",
    "        labels = list(set(y))\n",
    "        data = {label: [] for label in labels}\n",
    "        for f, label in zip(X, y):\n",
    "            data[label].append(f)\n",
    "        self.model = {\n",
    "            label: self.summarize(value)\n",
    "            for label, value in data.items()\n",
    "        }\n",
    "        return 'gaussian Naive Bayes train done!'\n",
    "    \n",
    "    #Calculate the probabilities\n",
    "    def calculate_probabilities(self, input_data):\n",
    "        # summaries:{0.0: [(5.0, 0.37),(3.42, 0.40)], 1.0: [(5.8, 0.449),(2.7, 0.27)]}\n",
    "        # input_data:[1.1, 2.2]\n",
    "        probabilities = {}\n",
    "        for label, value in self.model.items():\n",
    "            probabilities[label] = 1\n",
    "            for i in range(len(value)):\n",
    "                mean, stdev = value[i]\n",
    "                probabilities[label] *= self.gaussian_probability(input_data[i], mean, stdev)\n",
    "        return probabilities\n",
    "    \n",
    "    #Category\n",
    "    def predict(self, X_test):\n",
    "        label = sorted(\n",
    "            self.calculate_probabilities(X_test).items(),\n",
    "            key = lambda x: x[-1])[-1][0]\n",
    "        return label\n",
    "    \n",
    "    def score(self, X_test, y_test):\n",
    "        right = 0\n",
    "        for X, y in zip(X_test, y_test):\n",
    "            label = self.predict(X)\n",
    "            if label == y:\n",
    "                right += 1\n",
    "        return right / float(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NaiveBayes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gaussian Naive Bayes train done!'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: [(5.0, 0.3498917581542075),\n",
       "  (3.442424242424243, 0.40529099387395123),\n",
       "  (1.4545454545454548, 0.17423583650260666),\n",
       "  (0.2515151515151515, 0.11578771620935031)],\n",
       " 1.0: [(5.948648648648648, 0.5375729348990811),\n",
       "  (2.7594594594594595, 0.29081382496177344),\n",
       "  (4.25135135135135, 0.4830206876111376),\n",
       "  (1.3189189189189188, 0.19289800951411323)]}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(model.predict([4.4,  3.2,  1.3,  0.2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scikit-learn example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gaussian Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[4.4,  3.2,  1.3,  0.2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bernoulli Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = BernoulliNB()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43333333333333335"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[4.4,  3.2,  1.3,  0.2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43333333333333335"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multinomial Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[4.4,  3.2,  1.3,  0.2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ISLR_Python",
   "language": "python",
   "name": "islr_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
